{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Cup - Email Spam Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn import model_selection, naive_bayes, metrics, svm\n",
    "#from IPython.display import Image \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainingsdaten - Analyse\n",
    "\n",
    "Als erstes sollte der Trainingsdatensatz eingelesen werden und anschließend die ersten Zeilen ausgegeben werden.\n",
    "\n",
    "Aufgabe:\n",
    "\n",
    "1. Datei SMSSpamTrain.csv einlesen und ausgeben. Tipp: Achtet auf die Seperierung der Daten durch ein Semikolon ( ; )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten einlesen\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten ausgeben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da wir jetzt einen ersten Eindruck haben, wie der Datensatz aussieht, können wir durch geeignete Visualisierung weitere Informationen über den Datensatz gewinnen. Eine sinnvolle Information\n",
    "wäre es, herauszufinden, wie viele \"ham\" oder \"spam\" Mails in dem Datensatz vorhanden sind. Spam ist Spam, Ham ist Nicht-Spam.\n",
    "\n",
    "\n",
    "In Frage kommt hierfür z.B. die Methode df.plot(), mit der es möglich ist, durch den Parameter kind = {'bar' , 'hist' , 'box' , 'pie' , 'scatter'} die Art auszuwählen in der die Informationen dargestellt werden.\n",
    "\n",
    "\n",
    "In der unteren Zelle wurde zur Vereinfachung bereits mit pd.value_counts() die Anzahl der unterschiedlichen Werte der Spalte \"Label\" in der Variable \"anzahl_werte\" gespeichert und mit \n",
    "sort = True sortiert. \n",
    "\n",
    "Aufgabe:\n",
    "\n",
    "1. Probiert verschiedene Formen der Visualisierung aus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anzahl_werte=pd.value_counts(df[\"Label\"], sort= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interessant wäre es im Kontext eines Spam Filters, sich die Frequenz, also die Häufigkeit des Vorkommens von bestimmten Wörtern in Nicht-Spam und Spam anzeigen zu lassen. Dafür eignet sich die Klasse \"Counter\", die wir am Anfang importieren und in Kombination mit einem \"join\" zwischen \"ham\" oder \"spam\" und \"SMS\" die Top-20 Wörter ermittelt werden.\n",
    "\n",
    "Ein Beispiel, wie man das in Python umsetzen könnte und in einem bar.plot darstellen kann, haben wir unten bereitgestellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "count1 = Counter(\" \".join(df[df['Label']=='ham'][\"SMS\"]).split()).most_common(20)\n",
    "df1 = pd.DataFrame.from_dict(count1)\n",
    "df1 = df1.rename(columns={0: \"Wörter in nicht-Spam\", 1 : \"count\"})\n",
    "count2 = Counter(\" \".join(df[df['Label']=='spam'][\"SMS\"]).split()).most_common(20)\n",
    "df2 = pd.DataFrame.from_dict(count2)\n",
    "df2 = df2.rename(columns={0: \"Wörter in Spam\", 1 : \"count_\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.plot.bar(legend = False)\n",
    "y_pos = np.arange(len(df1[\"Wörter in nicht-Spam\"]))\n",
    "plt.xticks(y_pos, df1[\"Wörter in nicht-Spam\"])\n",
    "plt.title('Top-20 Wörter in nicht-Spam Mails')\n",
    "plt.xlabel('Wörter')\n",
    "plt.ylabel('Anzahl')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.plot.bar(legend = False, color = 'orange')\n",
    "y_pos = np.arange(len(df2[\"Wörter in Spam\"]))\n",
    "plt.xticks(y_pos, df2[\"Wörter in Spam\"])\n",
    "plt.title('Top-20 Wörter in Spam Mails')\n",
    "plt.xlabel('Wörter')\n",
    "plt.ylabel('Anzahl')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datenvorverarbeitung\n",
    "\n",
    "Bevor wir uns der Datentransformation widmen, ist es notwendig den Datensatz zunächst von der Groß- und Kleinschreibung und von der Punktuation zu bereinigen.\n",
    "\n",
    "Aufgabe:\n",
    "\n",
    "1. Daten bereinigen\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datentransformation\n",
    "\n",
    "Da die zwei Modelle Support Vector Machine und Naive Bayes beide numerische Werte voraussetzen, ist eine Transformation der Werte des Datensatzes notwendig. Eine Möglichkeit ist dafür ein\n",
    "\"Vokabular\" zu erstellen, der die einzelnen Wörter, die in der Spalte \"SMS\" vorkommen, beinhaltet. Anschließend wird mit Hilfe einer doppelten for-Schleife, das Vorkommen aller einzigartiger Wörter pro Index (also Zeile) ermittelt und in die Variable \"wort_anzahl_pro_sms\" gespeichert. Diese Variable muss dann, mit dem geeigneten Befehl, in ein DataFrame umgewandelt werden.\n",
    "\n",
    "Als erstes sollt Ihr selbstständig, durch zuhilfenahme nahme des Beispiels aus der Präsentation, das Vokabular erstellen. Der Code für den zweiten Teil der Transformation, wird von uns vorgegeben. Allerdings ist eure Aufgabe, durch Kommentare zu erklären, wöfür die einzelnen Bestandteile da sind und was sie bewirken. Zum Schluss sollt ihr das Data Frame erstellen und ausgeben.\n",
    "\n",
    "Aufgaben:\n",
    "\n",
    "1. Vokabular erstellen.\n",
    "2. for-Schleife kommentieren.\n",
    "3. Data Frame erstellen.\n",
    "\n",
    "### Vokabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der Initialisierung der Variable \"wort_anzahl_pro_sms\", wird die Länge, in Abhängigkeit der Länge des DataFrame, festgelegt. Dabei wird für jedes einzigartige Wort in vokabular eine Liste generiert die mit [0] gefüllt wird. Die Anzahl der [0] wird durch [0] * len(df['SMS']) definiert (in diesem Fall die Länge des DataFrame).\n",
    "\n",
    "Beispiel: [0]*5 = [0,0,0,0,0]\n",
    "\n",
    "### for-Schleife"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "wort_anzahl_pro_sms = {unique_word: [0] * len(df['SMS']) for unique_word in vokabular}\n",
    "\n",
    "for index, sms in enumerate(df['SMS']):\n",
    "   for word in sms:\n",
    "      wort_anzahl_pro_sms[word][index] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt wo wir das Vorkommen der einzelnen Wörter in einem Data Frame umgewandelt haben, ist der nächste Schritt, diese mit den Trainingsdaten zusammenzuführen. Überlegt euch welche Daten dafür benötigt werden.\n",
    "\n",
    "4. Trainingsdaten zusammenführen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zum Schluss ist es wichtig, wie oben bereits beschrieben, das alle Werte numerisch sind. Um das umzusetzen könnt Ihr wie wir das bereits aus den Übungen kennen, die Werte umwandeln.\n",
    "\n",
    "In diesem Fall ist es auch möglich, es später bei der Aufteilung der Trainingsdaten zu tun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeltraining & Bewertung\n",
    "\n",
    "In diesem Abschnitt sollen als erstes die Trainingsdaten für das Modeltraining in Test- und Trainingsdaten aufgeteilt werden. Das genaue Vorgehen kennt Ihr bereits aus den Übungen. Schaut euch an, inwieweit sich die Ergebnisse verändern, wenn ihr die Parameter verändert.\n",
    "\n",
    "Aufgabe:\n",
    "1. Aufteilung der Trainingsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weiter geht es mit dem Training der Modelle.\n",
    "\n",
    "Wir haben euch unten bereits einige Zeilen Code vorgegeben, in denen die Ergebnisse gespeichert und dann in einem Data Frame und einer Confusion Matrix ausgegeben werden. Initialisiert die Modelle (wählt dabei die Parameter aus) und übergebt dem Modell die Daten mit der Methode fit(). Probiert auch hier verschiedene Parameter aus und schaut welche Auswirkungen auftreten!\n",
    "\n",
    "Aufgabe:\n",
    "\n",
    "2. Die Modelle trainieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "score_train = svc.score(x_train, y_train)\n",
    "score_test = svc.score(x_test, y_test)\n",
    "recall_test = metrics.recall_score(y_test, svc.predict(x_test))\n",
    "precision_test = metrics.precision_score(y_test, svc.predict(x_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.matrix([score_train, score_test, recall_test, precision_test])\n",
    "models = pd.DataFrame(data = matrix, columns = \n",
    "             ['Train Accuracy', 'Test Accuracy', 'Test Recall', 'Test Precision'])\n",
    "models.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_confusion_test = metrics.confusion_matrix(y_test, svc.predict(x_test))\n",
    "pd.DataFrame(data = m_confusion_test, columns = ['Predicted 0', 'Predicted 1'],\n",
    "            index = ['Actual 0', 'Actual 1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes (MNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "score_train = bayes.score(x_train, y_train)\n",
    "score_test = bayes.score(x_test, y_test)\n",
    "recall_test = metrics.recall_score(y_test, bayes.predict(x_test))\n",
    "precision_test = metrics.precision_score(y_test, bayes.predict(x_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.matrix([score_train, score_test, recall_test, precision_test])\n",
    "models = pd.DataFrame(data = matrix, columns = \n",
    "             ['Train Accuracy', 'Test Accuracy', 'Test Recall', 'Test Precision'])\n",
    "models.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_confusion_test = metrics.confusion_matrix(y_test, bayes.predict(x_test))\n",
    "pd.DataFrame(data = m_confusion_test, columns = ['Predicted 0', 'Predicted 1'],\n",
    "            index = ['Actual 0', 'Actual 1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testdaten - Modelanwendung & Genauigkeit\n",
    "\n",
    "Bevor wir die Genauigkeit der Modelle testen, müssen die Testdaten zu erst eingelesen und dann wie die Trainingsdaten transformiert werden. Der Code für die Transformation der Testdaten, wird diesmal vorgegeben. Achtet darauf den Code anzupassen!\n",
    "\n",
    "Aufgaben:\n",
    "\n",
    "1. Testdaten einlesen\n",
    "2. Transformation anpassen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testdaten einlesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testdaten transformieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['SMS'] = df['SMS'].str.replace(\n",
    "   '\\W', ' ') # Entfernt Punktuation\n",
    "df['SMS'] = df['SMS'].str.lower() # Entfernt Groß- und Kleinschreibung\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SMS'] = df['SMS'].str.split()\n",
    "\n",
    "vokabular = []\n",
    "for sms in df['SMS']:\n",
    "   for word in sms:\n",
    "      vokabular.append(word)\n",
    "\n",
    "vokabular = list(set(vokabular))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "wort_anzahl_pro_sms = {unique_word: [0] * len(df['SMS']) for unique_word in vokabular}\n",
    "\n",
    "for index, sms in enumerate(df['SMS']):\n",
    "   for word in sms:\n",
    "      wort_anzahl_pro_sms[word][index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trans = pd.DataFrame(wort_anzahl_pro_sms)\n",
    "train_trans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model auf die Testdaten anwenden\n",
    "\n",
    "Im letzten Teil der Schulung, werden die Modelle oder eines der Modelle benutzt um vorherzusagen, ob die Mails in dem Testdatensatz Spam oder Nicht-Spam sind. Das Ergebniss sollte in einem Data Frame gespeichert werden. Gebt diesen aus und betrachtet, wie die Daten aussehen. Um das Ergebniss zu überprüfen, werden die Trainingsdaten als Vergleich genutzt. Überlegt euch wie ihr die beiden vergleichen und damit die Genauigkeit ermitteln könnt. \n",
    "\n",
    "Aufgaben:\n",
    "\n",
    "1. Modell zur Vorhersage nutzen.\n",
    "2. Vorhersage mit der Lösung vergleichen.\n",
    "3. Ergebnisse visualisieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Test = pd.DataFrame(data = prediction, columns = ['Spam'])\n",
    "Test1 = pd.DataFrame(data = prediction1, columns = ['Spam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLösung = pd.read_csv(\"SMSSpamTrain.csv\", sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_Class=pd.value_counts(ergebnisse['Richtig'], sort= True)\n",
    "count_Class.plot(kind = 'pie',  autopct='%0.1f%%')\n",
    "plt.title('Pie chart')\n",
    "plt.ylabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_Class=pd.value_counts(ergebnisse1['Richtig'], sort= True)\n",
    "count_Class.plot(kind = 'pie',  autopct='%0.1f%%')\n",
    "plt.title('Pie chart')\n",
    "plt.ylabel('')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eafb9e869005a8f6e6cc4776807b4aba4eafd0e8d02e7268aebcc2bedd4f3e65"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
