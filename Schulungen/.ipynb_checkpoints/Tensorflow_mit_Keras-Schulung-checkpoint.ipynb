{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a932dbd",
   "metadata": {},
   "source": [
    "### Schulung Machine Learning Libraries -Tensorflow mit Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba212804",
   "metadata": {},
   "source": [
    "##### Ausgangsinformation: Bitte immer die Kommentare IM Code durch den tatsächlichen Code ersetzen. An manchen Stellen dürfen keine Kommentare (z.B. #Eure Ergänzungen) mehr beim Ausführen im Code stehen!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884faafc",
   "metadata": {},
   "source": [
    "**0.** Ladet euch die Winrar-Datei \"Bilder\" aus Moodle herunter und entpackt diese. Speichert den entpackten Ordner in dasselbe Verzeichnis, indem auch euer Notebook liegt (falls möglich)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475a7525",
   "metadata": {},
   "source": [
    "**1.** Zunächst müssen wir die benötigten Module importieren und TensorFlow per !pip install installieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c24ed10",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff99227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926ed8d1",
   "metadata": {},
   "source": [
    "**2.** Nun wollen wir uns zur Übersicht die enthaltenen Unterordner von dem Ordner \"Bilder\" ausgeben lassen. Dies lässt sich mit dem Befehl `ls \"Ordnername\"` durchführen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db786156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4b2e119",
   "metadata": {},
   "source": [
    "Jetzt müssten in der Ausgabe die beiden Unterordner \"Hund\" und \"Katze\" zu sehen sein."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6169cc",
   "metadata": {},
   "source": [
    "**3.** Bevor mit den Bildern gearbeitet werden kann, ist es ratsam, alle schlecht kodierten Bilder zu entfernen. Dafür sortieren wir alle Bilder aus, welche nicht dem JFIF (JPG/JPEG) Format entsprechen. Dies trifft bei unseren Datensätzen nicht zu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e05c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_skipped = 0\n",
    "for ordner_name in (\"Hund\", \"Katze\"):\n",
    "    ordner_pfad = os.path.join(\"Bilder\", ordner_name)\n",
    "    for oname in os.listdir(ordner_pfad):\n",
    "        opfad = os.path.join(ordner_pfad, oname)\n",
    "        try:\n",
    "            oobj = open(opfad, \"rb\")\n",
    "            is_jfif = tf.compat.as_bytes(\"JFIF\") in oobj.peek(10)\n",
    "        finally:\n",
    "            oobj.close()\n",
    "\n",
    "        if not is_jfif:\n",
    "            num_skipped += 1\n",
    "            os.remove(opfad)\n",
    "\n",
    "print(\"Gelöschte Bilder: %d\" % num_skipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77181784",
   "metadata": {},
   "source": [
    "**4.** Als nächsten Schritt wollen wir die Bilder in ein Dataset einlesen. \n",
    "Vorher müssen wir aber noch die Bilder in eine einheitliche Größe bringen. Wir wollen hier eine Größe von 180x180 festlegen `image_size = (Größe, Größe)`. Außerdem wollen wir die Bilder für das Modell in mehrere Batches aufteilen (`batch_size = Anzahl Batches`). Hier wählen wir 16 Batches aus. Zudem wollen wir einen `validation_split` von 0.2 bei den Trainings- und Validierungsdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef929170",
   "metadata": {},
   "outputs": [],
   "source": [
    "#einheitliche Größe festlegen\n",
    "\n",
    "#Größe der Batches festlegen\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"Bilder\",\n",
    "    validation_split=#Größe des Splits,\n",
    "    subset=\"training\",\n",
    "    seed=9,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"Bilder\",\n",
    "    validation_split=#Größe des Splits,\n",
    "    subset=\"validation\",\n",
    "    seed=9,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bae3f0",
   "metadata": {},
   "source": [
    "**5.** Nun können wir einen kleinen Blick in die eingelesenen Trainingsdaten werfen. Ihr werdet feststellen, dass die Hundebilder mit `0` und die Katzenbilder mit `1` gekennzeichnet wurden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de375474",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(int(labels[i]))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623a5fe1",
   "metadata": {},
   "source": [
    "**6.** Da wir in dieser Schulung mit einem sehr kleinen Dataset arbeiten, kann es zu Ungenauigkeiten bei den späteren Vorhersagen unseres Modells kommen. Um dem etwas entgegen zu  wirken führen wir eine Image Data Augmentation durch. Diese Funktion erstellt später aus unseren Input-Bildern durch Kippen (`layers.RandomRotation(0.1)`) und horizontales Spiegeln (`layers.RandomFlip(\"horizontal\")`) neue Bilder für den Trainigsprozess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253d9c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        #horizontales Spiegeln,  \n",
    "        \n",
    "        #Kippen der Bilder, \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64af84d5",
   "metadata": {},
   "source": [
    "**7.** Im Folgenden Code-Segment könnt ihr euch die Funktionsweise von `data_augmentation` beispielhaft für ein zufälliges Bild anzeigen lassen. Beachtet die minimalen Drehungen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316bc8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "for images, _ in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        augmented_images = data_augmentation(images)\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "        plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ea05cc",
   "metadata": {},
   "source": [
    "**8.** Als nächsten Schritt werden die Datensätze für eine bessere Performance angepasst. Dafür wird die Zeit, in der die Daten produziert werden, von der Zeit, in der die Daten weiterverarbeitet werden, entkoppelt. Dadurch wird das Risiko von Eingabe- und Ausgabefehlern reduziert. Dafür ergänzen wir die beiden Befehle jeweils um `prefetch(buffer_size=16)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f40070e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.#Eure Ergänzungen\n",
    "val_ds = val_ds.#Eure Ergänzungen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bdd5fe",
   "metadata": {},
   "source": [
    "**9.** Nun können wir mit dem Bauen des Modells anfangen. Dort wird zunächst ein Keras-Tensor instanziiert (`inputs = keras.Input(shape=input_shape)`). Anschließend übergeben wir der Variablen x unsere data_augmentation (`x = data_augmentation(inputs)`). Danach müssen wir die Daten noch normalisieren (zwischen 0 und 1). Da unsere Farben RGB aufweisen (und daher eine Pixelweite von 0-255 besitzen), müssen wir diese mit 255 dividieren, um in den gewünschten Wertebreich zu gelangen (`x = layers.Rescaling(1.0 / 255)(x)`). Unser Modell basiert auf der funktionellen API von Keras. Deswegen wird `x` beginnend vom `Rescaling` Layer immer von Layer zu Layer weiter gegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1599c05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_shape, num_classes):\n",
    "    #Keras-Tensor instanziieren \n",
    "     \n",
    "    #Data Augmentation an x übergeben\n",
    "\n",
    "    \n",
    "    #RGB zu gewünschten Wertebereich normalisieren\n",
    "    \n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  \n",
    "\n",
    "    for size in [128, 256, 512, 728]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "       \n",
    "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  \n",
    "        previous_block_activation = x  \n",
    "\n",
    "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    if num_classes == 2:\n",
    "        activation = \"sigmoid\"\n",
    "        units = 1\n",
    "    else:\n",
    "        activation = \"softmax\"\n",
    "        units = num_classes\n",
    "\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(units, activation=activation)(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model = make_model(input_shape=image_size + (3,), num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9682f5",
   "metadata": {},
   "source": [
    "**10.** Nachdem wir das Modell erfolgreich erstellt haben, können wir dieses trainieren. Epochs definieren, wie häufig der Trainingsprozess durchlaufen werden soll. Wir setzen diesen Wert auf 5 (`epochs = Anzahl Trainingsdurchläufe`). Callbacks können genutzt werden, um verschiedene Aktionen in verschiedenen Trainingsschritten durchzuführen. Wir nutzen diese Möglichkeit und erstellen einen `ModelCheckpoint`. Dieser kann das Modell oder verschiedene Gewichtungen speichern, damit bspw. eine spätere Weiterarbeit an demselben Punkt ermöglicht wird."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f750edac",
   "metadata": {},
   "source": [
    "Danach wird das Modell noch kompiliert. Als optimizer wollen wir Adam mit einer Learnrate von 0.01 nutzen (`optimizer=keras.optimizers.Adam(0.01)`).\n",
    "Zum Schluss müssen wir dieses Modell nur noch trainieren `model.fit()`. Als Parameter übergeben wir `train_ds, epochs=epochs, callbacks=callbacks, validation_data=val_ds`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c2ef0e",
   "metadata": {},
   "source": [
    "**Achtung:** Es könnte je nach Rechenleistung zu erhöhten Ausführungszeiten kommen. Wenn ihr ungeduldig werdet, könnt ihr vielleicht schon mal mit dem Quiz beginnen. \n",
    "\n",
    "Zudem wird eine Warnung ausgegeben, welche aber ignoriert werden kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377eb704",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anzahl der Epochs definieren\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"),\n",
    "]\n",
    "model.compile(\n",
    "    #optimizer mit adam angeben\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.fit(\n",
    "    #Parameter angeben\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d60846",
   "metadata": {},
   "source": [
    "Was könnten Gründe für die geringe `val_accuracy` sein? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2016d1",
   "metadata": {},
   "source": [
    "**11.** Dieses trainierte Modell könnten wir nun theoretisch mit neuen Daten testen und schauen, ob das Modell das angegebene Bild als Hund bzw. Katze richtig identifiziert. Da unser Trainingsdatenset nur sehr klein war, wird die Ausgabe hier sehr ungenau sein. Deshalb beachten wir diese nicht weiter. Falls ihr die Schulung nochmal mit dem kompletten Datensatz von Kaggle durchführen wollt, könnt ihr am Ende gerne diese Prediction-Methode anwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdae98a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''img = keras.preprocessing.image.load_img(\n",
    "    \"bild.jpg\", target_size=image_size\n",
    ")\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)  \n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = predictions[0]\n",
    "print(\n",
    "    \"This image is %.2f percent cat and %.2f percent dog.\"\n",
    "    % (100 * (1 - score), 100 * score)\n",
    ")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b08517",
   "metadata": {},
   "source": [
    "## Nun wechselt bitte in das nächste Notebook (Scikit-Learn-Schulung)\n",
    "#### Datensatz (angepasst) von: https://www.kaggle.com/shaunthesheep/microsoft-catsvsdogs-dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
