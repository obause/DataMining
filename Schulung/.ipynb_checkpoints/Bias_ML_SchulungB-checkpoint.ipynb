{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a77edc18-8b2b-4ef8-a7dd-73993c203c77",
   "metadata": {},
   "source": [
    "# Bias in Machine Learning Schulungsoption B Lösung\n",
    "### Ethischer Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ca0000-a5b5-4f92-b7a2-2e678896b853",
   "metadata": {},
   "source": [
    "### 1 Einführung\n",
    "\n",
    "In diesem Teil der Übung soll der ethische Bias etwas näher betrachtet werden.    \n",
    "Als Grundlage dient ein Dataset mit ~2 Millionen Kommentaren von Online-Plattformen.    \n",
    "    \n",
    "Mit diesen wird ein Modell trainiert, das anhand eines Kommentars bewerten soll, ob dieser \"toxisch\" oder \"nicht toxisch\" ist. Also ein Kommentar negative Ausdrucksweisen enthält oder nicht.\n",
    "    \n",
    "Da es hier nicht direkt im das trainieren des Modells gehen soll ist dies bereits vorgegeben."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288badc6-f12e-4d3a-8dd3-2664f4542052",
   "metadata": {},
   "source": [
    "#### 1.1 Dataset laden und vorbereiten\n",
    "Führt den unten angegebenen Code aus. Da das Dataset sehr groß ist kann es bei der Verarbeitung etwas länger dauern (ca. 30 Sek.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "66534bdd-f526-4108-bbb7-e2a28ffa46d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Seed setzen, um immer die gleichen Ergebnisse zu erhalten\n",
    "np.random.seed(0)\n",
    "\n",
    "# Daten laden und benötigte Spalten extrahieren\n",
    "data = pd.read_csv(\"comments_data.csv\")\n",
    "comments = data[\"comment_text\"]\n",
    "target = (data[\"target\"]>0.7).astype(int)\n",
    "\n",
    "# Daten in Trainings- und Test-Sets aufteilen (70:30)\n",
    "comments_train, comments_test, y_train, y_test = train_test_split(comments, target, test_size=0.30, stratify=target)\n",
    "\n",
    "# Alle einzelnen Wörter aus allen Kommentaren extrahieren und Wörterbuch mit ihrer Häufigkeit erstellen\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(comments_train)\n",
    "\n",
    "# Dictionary für das Trainings- und Test-Set mit der Anzahl der Wörter erstellen\n",
    "X_train = vectorizer.transform(comments_train)\n",
    "X_test = vectorizer.transform(comments_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3afdfe-9b07-4dc1-867c-9faa4a4134f1",
   "metadata": {},
   "source": [
    "#### 1.2 Daten betrachten\n",
    "Nun wollen wir uns die erstellten Daten anschauen und lernen mit diesen zu arbeiten. Mit `vectorizer.vocabulary_` bekommt ihr das Wörterbuch mit der Häufigkeit der einzelnen Wörter als Dictionary zurück (Dies wertet ihr später noch benötigen).    \n",
    "    \n",
    "Wie oft kommt in unserem Dataset das Wort `love` und das Wort `dumbass` vor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8279de8-2720-4d39-b39e-a306a2cd7e2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl Wort love: 31279\n",
      "Anzahl Wort dumbass: 16848\n"
     ]
    }
   ],
   "source": [
    "print(\"Anzahl Wort love:\", vectorizer.vocabulary_['love'])\n",
    "print(\"Anzahl Wort dumbass:\", vectorizer.vocabulary_['dumbass'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776b3139-0982-4cdf-a52a-11bf3af7c88a",
   "metadata": {},
   "source": [
    "Gebt euch ein paar Kommentare aus der Series(Dataframe mit einer Spalte) `comments_train` aus. Würdet ihr von diesen Kommentare welche als toxisch einstufen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82018f91-6828-4400-9aca-af57bc4fc17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Too dumb to even answer.  -> Toxisch\n",
      "No they aren't.  -> Nicht toxisch\n",
      "Idiot.  -> Toxisch\n"
     ]
    }
   ],
   "source": [
    "print(comments_train.iloc[22], \" -> Toxisch\")\n",
    "print(comments_train.iloc[17], \" -> Nicht toxisch\")\n",
    "print(comments_train.iloc[28], \" -> Toxisch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde995ac-17f7-401a-8d2a-61c17a054812",
   "metadata": {},
   "source": [
    "### 2 Model trainieren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8d83e0-f2f2-4562-bacd-f17e5630749a",
   "metadata": {},
   "source": [
    "#### 2.1 Model trainieren und Genauigkeit überprüfen\n",
    "Führt den unten angegebenen Code nun aus, um ein einfaches Model zu trainieren. Zusätzlich berechnen wir die Genauigkeit des Models auf den Testdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b8d1479-0f7c-42b0-b4c6-3c665aca7eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genauigkeit: 0.9304755967877966\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression(max_iter=2000)\n",
    "classifier.fit(X_train, y_train)\n",
    "score = classifier.score(X_test, y_test)\n",
    "print(\"Genauigkeit:\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16aed4e5-e517-4939-a04e-7c4425df1b89",
   "metadata": {},
   "source": [
    "Ziemlich genau 93% der Kommentare werden von unserem Model korrekt erkannt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365ce2c1-ea8b-4f6b-b0de-71aa5a98e4c0",
   "metadata": {},
   "source": [
    "#### 2.2 Model ausprobieren\n",
    "Versucht nun ein paar eigene Kommentare an das Model zu übergeben und von diesem die Klassifizierung zurück zu erhalten.    \n",
    "    \n",
    "Da die Kommentare nur auf englischer Sprache basieren müsst ihr natürlich auch einen englischen Kommentar verfassen.    \n",
    "Beispiele:\n",
    " - \"I love Data Mining\"\n",
    " - \"Corona is stupid\"\n",
    " \n",
    "Versucht unterschiedliche Kommentare zu testen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d7c70ef-b91c-48cb-a29a-5aa79e56373d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion, um einen String von dem Modell zu Klassifizieren (Hier nichts verändern)\n",
    "def classify_string(string, investigate=False):\n",
    "    prediction = classifier.predict(vectorizer.transform([string]))[0]\n",
    "    if prediction == 0:\n",
    "        print(\"NICHT TOXISCH:\", string)\n",
    "    else:\n",
    "        print(\"TOXISCH:\", string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "23356798-298f-45c5-a1f2-7894d464b308",
   "metadata": {},
   "outputs": [],
   "source": [
    "mein_kommentar = \"<Hier euer Kommentar>\"\n",
    "mein_kommentar = \"Corona is stupid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0da29d7c-b389-426d-8d6e-cfd819d3477d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOXISCH: Corona is stupid\n"
     ]
    }
   ],
   "source": [
    "classify_string(mein_kommentar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9161348f-dcab-439f-bc67-436cfd23b768",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71f2c9ab-b2e4-4052-86d7-b40adc424615",
   "metadata": {},
   "source": [
    "### 3 Genauere Betrachtung des Modells\n",
    "\n",
    "Nachdem ihr das Modell nun etwas getestet habt, betrachten wir das Modell einmal etwas näher, um zu verstehen wie das Modell Entscheidungen trifft.    \n",
    "    \n",
    "Das Modell fügt jedem der einzelnen Wörter in den Kommentaren einen Koeffizienten hinzu. Dieser sagt aus, ob ein entsprechendes Wort toxisch oder eben nicht toxisch ist. Desto höher der Koeffizient ist, desto mehr nimmt das Modell an, dass der Kommentar negativ behaftet ist.    \n",
    "Ihr sollt nun ein Dataframe erstellen, das die Wörter mit den höchsten Koeffizienten anzeigt.\n",
    "\n",
    "Benötigte Objekte:\n",
    " - `vectorizer.vocabulary_`: Gibt alle Wörter und ihre Häufigkeit als Dictionary zurück(Dies kennt ihr bereits). Wir benötigen nur die Wörter-Spalte alphabetisch sortiert als Liste.\n",
    " - `classifier.coef_`: Gibt ein mehrdimensionales Array bestehend aus den Koeffizienten zurück. Wir benötigen nur das erste Array.    \n",
    "     \n",
    "Erstellt nun ein Dataframe mit zwei Spalten: Einmal Spalte \"Wort\" mit den Wörtern und einmal die Spalte \"Koeffizient\" mit den entsprechenden Werten.    \n",
    "    \n",
    "**Hilfestellungen für die Wörter-Spalte:** \n",
    "  - <dict>.keys() gibt nur die Keys aus einem Dictionary zurück\n",
    "  - list() wandelt die Keys in eine Liste um\n",
    "  - sorted() sortiert die Liste alphabetisch (Damit die Einträge in der Liste zu den Koeffizienten passen muss diese so sortiert werden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1fbef4f7-e265-424d-9c0b-cce4b9c8cfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spalte für die Wörter und Spalte für die Koeffizienten erstellen\n",
    "words = sorted(list(vectorizer.vocabulary_.keys()))\n",
    "coeffs = classifier.coef_[0]\n",
    "# Dataframe erstellen\n",
    "df = pd.DataFrame({\"Wort\": words, \"Koeffizient\": coeffs})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8742cf-2c15-4522-b9ce-f1c3a590e06a",
   "metadata": {},
   "source": [
    "Sortiert nun das Dataframe absteigend nach der Spalte Koeffizient und lasst euch die ersten 15 Datensätze anzeigen.    \n",
    "**Tipp:** Die Funktion `sort_values()`von pandas kann euch dabei helfen: [Dokumentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a390db76-d9d5-4256-9452-bd0a6f1e7d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wort</th>\n",
       "      <th>Koeffizient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49789</th>\n",
       "      <td>stupid</td>\n",
       "      <td>9.278404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25847</th>\n",
       "      <td>idiot</td>\n",
       "      <td>8.605696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25858</th>\n",
       "      <td>idiots</td>\n",
       "      <td>8.602204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49802</th>\n",
       "      <td>stupidity</td>\n",
       "      <td>7.553492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25850</th>\n",
       "      <td>idiotic</td>\n",
       "      <td>7.005250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38317</th>\n",
       "      <td>pathetic</td>\n",
       "      <td>6.554432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12907</th>\n",
       "      <td>crap</td>\n",
       "      <td>6.490130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16844</th>\n",
       "      <td>dumb</td>\n",
       "      <td>6.359553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34211</th>\n",
       "      <td>moron</td>\n",
       "      <td>6.332492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20745</th>\n",
       "      <td>fools</td>\n",
       "      <td>6.278988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25687</th>\n",
       "      <td>hypocrite</td>\n",
       "      <td>6.157440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34215</th>\n",
       "      <td>morons</td>\n",
       "      <td>6.153712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25932</th>\n",
       "      <td>ignorant</td>\n",
       "      <td>5.916985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20737</th>\n",
       "      <td>fool</td>\n",
       "      <td>5.898177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13692</th>\n",
       "      <td>damn</td>\n",
       "      <td>5.740614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Wort  Koeffizient\n",
       "49789     stupid     9.278404\n",
       "25847      idiot     8.605696\n",
       "25858     idiots     8.602204\n",
       "49802  stupidity     7.553492\n",
       "25850    idiotic     7.005250\n",
       "38317   pathetic     6.554432\n",
       "12907       crap     6.490130\n",
       "16844       dumb     6.359553\n",
       "34211      moron     6.332492\n",
       "20745      fools     6.278988\n",
       "25687  hypocrite     6.157440\n",
       "34215     morons     6.153712\n",
       "25932   ignorant     5.916985\n",
       "20737       fool     5.898177\n",
       "13692       damn     5.740614"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe nach Koeffizient absteigend sortieren\n",
    "df_sorted = df.sort_values(by='Koeffizient', ascending=False)\n",
    "\n",
    "# Erste 15 Datensätze des sortierten Dataframes ausgeben\n",
    "df_sorted.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1cdaa3-adb5-4bf6-99b8-60adb0eefecf",
   "metadata": {},
   "source": [
    "Schaut euch die Wörter an. Gibt es Wörter die überraschend sind? Sind bei euch welche dabei, die nicht dabei sein sollten?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b205eb3-95ad-4b42-9ea5-6814d13346b4",
   "metadata": {},
   "source": [
    "### 4 Bias finden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047b0879-0340-4e82-a671-e59effc78dd6",
   "metadata": {},
   "source": [
    "#### 4.1 Kommentare genauer analysieren\n",
    "Wir wollen nun versuchen einen Bias in unserem Modell zu finden. Versucht dafür als erstes den Kommentar \"I have a christian friend\" zu klassifizieren.    \n",
    "Nutzt dafür wieder die Methode `classify_string()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a22ddf4e-af24-4870-8c73-69d5f826a30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NICHT TOXISCH: I have a christian friend\n"
     ]
    }
   ],
   "source": [
    "kommentar = \"I have a christian friend\"\n",
    "\n",
    "classify_string(kommentar)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a362b417-bdc1-4902-b7e2-29756e26e826",
   "metadata": {},
   "source": [
    "Lasst euch nun die Koeffizienten der einzelnen Wörter in dem Kommentar ausgeben. Dafür könnt ihr euer zuvor erstelltes Dataframe mit der Liste aller Wörter und ihren Koeffizienten nutzen.    \n",
    "    \n",
    "**Hilfestellungen:**\n",
    " - `<string>.split()`: Teilt einen String in eine Liste der einzelnen Wörter (Trennung bei den Leerzeichen)\n",
    " - Um den Eintrag im Dataframe zu finden gibt es verschiedene Möglichkeiten: `<df>.<spalte>.isin(<liste der Wörter>)` gibt euch eine series zurück bei der der Index in jedem Datensatz einen boolschen Wert beinhaltet und True bzw. False ist, je nachdem ob das Wort in dem Satz vorkommt. Dies könnt ihr auf das Dataset anwenden um die Koeffizienten anzeigen zu lassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "21b3735e-ae6d-44a2-8d3f-20345e794dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wort</th>\n",
       "      <th>Koeffizient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10293</th>\n",
       "      <td>christian</td>\n",
       "      <td>-0.040827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24049</th>\n",
       "      <td>have</td>\n",
       "      <td>-0.072302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21256</th>\n",
       "      <td>friend</td>\n",
       "      <td>-0.131335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Wort  Koeffizient\n",
       "10293  christian    -0.040827\n",
       "24049       have    -0.072302\n",
       "21256     friend    -0.131335"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sorted[df_sorted.Wort.isin(kommentar.split())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1206e2-8da3-4dc8-9c5a-6cf698603a23",
   "metadata": {},
   "source": [
    "Versucht als nächstes den Kommentar \"I have a muslim friend\" auf die gleiche Weise zu bewerten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "08423f34-d33c-4e46-bcec-fe1a6335587d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOXISCH: I have a muslim friend\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wort</th>\n",
       "      <th>Koeffizient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34692</th>\n",
       "      <td>muslim</td>\n",
       "      <td>1.768562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24049</th>\n",
       "      <td>have</td>\n",
       "      <td>-0.072302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21256</th>\n",
       "      <td>friend</td>\n",
       "      <td>-0.131335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Wort  Koeffizient\n",
       "34692  muslim     1.768562\n",
       "24049    have    -0.072302\n",
       "21256  friend    -0.131335"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kommentar2 = \"I have a muslim friend\"\n",
    "\n",
    "classify_string(kommentar2)\n",
    "df_sorted[df_sorted.Wort.isin(kommentar2.split())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589ebb1d-4bf3-4a99-b995-a06e2a9b4895",
   "metadata": {},
   "source": [
    "Testet dieses Vorgehen nun mit weiteren Kommentaren. Beispielweise könnt ihr \"I have a white/black friend\" testen, aber versucht euch gerne etwas eigenes zu überlegen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505b61f6-f2ad-4b18-bf19-8d52c04b688d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baf1ff2-3c10-41ea-b247-9ab62ca8eeee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30d4bd79-88dd-4d06-89e9-868e9e70c92a",
   "metadata": {},
   "source": [
    "#### 4.2 Bias identifizieren\n",
    "Nun wollen wir bewerten was wir gerade herausgefunden haben.\n",
    "  \n",
    "##### Wie klassifiziert das Modell eure Kommentare?    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b19a372-6cda-429d-95ac-109113293380",
   "metadata": {},
   "source": [
    "**Antwort** \"I have a muslim friend\" wird als toxisch markiert während \"I have a christian friend\" nicht als toxisch markiert wurde. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5422fe1-fbbb-48ef-8c6b-5ae40f9f94cd",
   "metadata": {},
   "source": [
    "##### Konntet ihr einen potenziellen Bias in dem Model finden? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ca8fba-d12d-4dd8-86e2-d971cd7b3491",
   "metadata": {},
   "source": [
    "**Antwort:** Keiner dieser Kommentare sollte als toxisch markiert werden, aber das Modell idetifiziert fälschlicherweise einen Kommentar als toxisch. Das ist ein Zeichen von einem Bias. Das Modell ist gegenüber dem Schlüsselwort `muslim` voreingenommen, während das gleiche mit dem Wort `christian` nicht passiert. Ebenso für `black/white`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba149d0-c72f-4b1f-a98b-23ea6c4950c4",
   "metadata": {},
   "source": [
    "##### Stellt eine Vermutung an wieso das Model einen Bias aufweist.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5263fb-2e23-43da-9b0a-79df0fc939ee",
   "metadata": {},
   "source": [
    "**Antwort:**    \n",
    "Da die Daten mit denen das Modell trainiert wurde auf Kommentaren aus Online-Plattformen basieren ist es vorstellbar, dass auf diesen Plattformen Kommentare, die sich auf den Islam beziehen von bestimmten Personengruppen verfasst werden die schlecht und abwertend über diese Glaubensrichtung reden, während dies beim christlichen Glauben weniger der Fall ist.     \n",
    "Das gleiche scheint auch bei der Hautfarbe der Fall zu sein.    \n",
    "    \n",
    "Da diese Wörter häufiger zusammen mit anderen negativen Begriffen in einem Kommentar aufgetaucht sind, hat das Modell von den Kommentaren unbeabsichtigt gelernt selbst auch diskriminierende Bewertungen zu machen und bestimmte Vorurteile bzw. Voreingenommenheit zu übernehmen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b0ac05-513a-4698-b61a-fa2feb8225a2",
   "metadata": {},
   "source": [
    "##### Um welche Art von Bias könnte es sich handeln?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbe9fd6-f87e-49eb-8bdf-af23ce7e923e",
   "metadata": {},
   "source": [
    "**Antwort:**    \n",
    "Prejudice Bias (Voreingenommenheit): Die zum Trainieren des Systems verwendeten Daten spiegeln vorhandene Vorurteile, Stereotypen und/oder fehlerhafte gesellschaftliche Annahmen wider, wodurch dieselben Vorurteile aus der realen Welt in das maschinelle Lernen selbst einfließen."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
