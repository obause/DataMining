{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übung 3 - Datenvorbereitung, Modelltraining und -bewertung\n",
    "\n",
    "Notwendige Bibliotheken werden geladen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lesen Sie erneut die Kundendaten ein und geben Sie die ersten Zeilen aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Business Understanding: Was ist Ihre Zielvariable?\n",
    "\n",
    "Ziel ist es ein Modell zu entwickeln, welches für das Unternehmen die umsatzstärksten Kunden findet. Es wird festgelegt, dass ein Kunde als umsatzstark gilt, wenn der Gesamtumsatz über 300 liegt.\n",
    "\n",
    "Dafür soll ein neues Attribut \"high revenue\" über den Gesamtumsatz eines Kundens \"total_sum\" berechnet werden. Ist der Schwellwert von 300 überschritten, so ist \"high revenue\" mit \"1\" gekennzeichnet, sonst \"0\". Hierfür können Sie die numpy Funktion np.where(Bedingung,wenn Wahr, wenn falsch) verwenden.\n",
    "\n",
    "Fügen Sie die Spalte \"high revenue\" dem Datensatz hinzu und überprüfen Sie das Ergebnis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Verteilung der Zielvariable\n",
    "\n",
    "Zunächst wollen wir einmal wissen, wie \"high revenue\" in den Daten verteilt ist.\n",
    "\n",
    "Dazu werden die Ausprägungen von \"high revenue\" gezählt über die groupby Funktion und als Balkendiagramm dargestellt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = df.groupby('high revenue').agg({'count':'sum'})\n",
    "\n",
    "bc.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Datenreduktion & -bereinigung\n",
    "\n",
    "Bezüglich des Data Understanding wurde der Fachbereich befragt und dort wurde festgelegt, dass nicht alle vorhandenen Attribute relevant sind. Es sollen im Datensatz nur noch folgende verwendet werden:\n",
    "\n",
    "- gender\n",
    "- age_first_order\n",
    "- user_agent_brand, user_agent_os\n",
    "- campaign\n",
    "- pages_visited_average\n",
    "- high revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun folgt die Datensäuberung. Lassen Sie sich fehlende Werte anzeigen und führen Sie folgende Schritte der Datensäuberung durch:\n",
    "\n",
    "1. Fehlende Werte (NaN) mit häufigsten Wert ersetzen (dfClean['Attribut'].mode()[0])\n",
    "Das Ergebnis sollte in der Variable dfClean stehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der Datentransformation wollen wir eine Kodierung in numerische Werte vornehmen (auch wenn wir hier nicht ordinale Attribute haben). Dazu nutzen wir den LabelEncoder(). Wenden Sie den ebenfalls für user_agent_os und user_agent_brand an und schauen Sie sich an, wie sinnvoll Sie das Ergebnis finden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "labelenc = preprocessing.LabelEncoder()\n",
    "\n",
    "dfPrepared = dfClean.copy()\n",
    "\n",
    "labelenc.fit(dfPrepared.gender)\n",
    "dfPrepared['gender'] = labelenc.transform(dfPrepared.gender)\n",
    "\n",
    "#### Hier die Kodierungen für user_agent_os und user_agent_brand\n",
    "\n",
    "dfPrepared[\"campaign\"] = dfPrepared[\"campaign\"].astype(int)\n",
    "\n",
    "\n",
    "dfPrepared.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Teilung in Trainings- & Testdaten\n",
    "Das Zielattribut wird von dem Datenframe seperiert. Trainings- und Testdaten sind im Verhältnis 70:30 aufgeteilt. Über die Option \"stratify\" ist die Verteilung des Zielattributes identisch zu der in den Ausgangsdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = dfPrepared.drop(['high revenue'], axis = 1)\n",
    "y = dfPrepared['high revenue']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y,\n",
    "                                    random_state = 101, stratify = y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Entscheidungsbaum-Modell\n",
    "So wird bspw. ein Entscheidungsbaum (engl. decision tree) mit dem gesplitteten Datenset trainiert und anschließend auf den Testdaten evaluiert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state = 10)\n",
    "dt_model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = dt_model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 Bewertung des Modells\n",
    "Anschließend folgt die Bewertung des Modells auf den Testdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die absolute Verteilung ist in Form einer Confusion Matrix dargestellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie bewerten Sie die Güte des Modells?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 k-fold Cross-Validation\n",
    "Schritt 5 wird mit einer k-fold Cross Validation mit k = 10 wiederholt. Zuvor bezog sich der Score nur auf einen Testdatensatz. Durch Cross-Validation werden 10 Scores durch 10 Iterationen erzeugt. Anschließend ist der Mittelwert der Scores ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "scores = cross_validate(estimator = dt_model, X = x, y = y, cv = 10, n_jobs = 4,\n",
    "                        return_estimator = True, return_train_score = True)\n",
    "\n",
    "dfScores = pd.DataFrame.from_dict(scores)\n",
    "dfScores['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vergleichen Sie nun den Score der Kreuzvalidierung mit dem obigen. Was sagt Ihnen der Unterschied? Lassen Sie sich die einzelnen Scores anzeigen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warum sollten Sie die Leave-one-out Variante ggf. nicht testen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
